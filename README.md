# V.I.V.I.A

## Overview
V.I.V.I.A (Versatile and Interactive Voice Integrated Assistant) is a project created to explore the potential of AI, particularly in building a virtual assistant. This leverages the advanced capabilities of OpenAI's GPT-4 and ElevenLabs’ Multilingual Voice v2 APIs, offering unique, multilingual interactions.

## Features
- **AI-Powered Conversations**: Engage with an assistant powered by the latest GPT-4 model for natural and informative interactions.
- **Multilingual Support**: Utilizes ElevenLabs’ Multilingual Voice v2 for seamless communication in multiple languages.
- **Custom Synthetic Voice**: Integration with ffmpeg to asynchronously generate speech, enhancing the user experience with a custom ElevenLabs synthetic voice.

## Requirements
- Python 3 (built using 3.12)
- OpenAI API key
- ElevenLabs API key
- ffmpeg installed on your system or environment (Recommended)

## Installation
1. Clone this repository to your local machine.
2. Install required Python packages: `pip install -r requirements.txt`
   ( I recommend setting up an venv or conda environment )
3. Ensure ffmpeg is correctly installed and accessible in your PATH.
4. Set up your OpenAI and ElevenLabs API keys as environment variables.

## Usage
To start V.I.V.I.A, run the main script from your (environment) terminal:
```
python "New_Code/vivia_interaction.py"
```
Follow the on-screen prompts to interact with your assistant.

## Contribution
Your contributions are welcome! If you have suggestions for improvements or have found bugs, please open an issue or submit a pull request.

## Acknowledgments
A special thank you to OpenAI and ElevenLabs for providing the APIs that made this project possible. This project was created for educational purposes to understand the workings and integration of AI in virtual assistants.

---


